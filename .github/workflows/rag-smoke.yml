name: "RAG Smoke (Phase-10)"

on:
  push:
    branches: [ "**" ]   # временно — на любые бранчи
  pull_request:
    branches: [ "**" ]
  workflow_dispatch:

concurrency:
  group: "${{ github.workflow }}-${{ github.ref }}"
  cancel-in-progress: true

jobs:
  rag-smoke:
    runs-on: ubuntu-latest
    timeout-minutes: 40

    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: "Install deps"
        shell: bash
        env:
          PIP_DISABLE_PIP_VERSION_CHECK: "1"
          PIP_NO_INPUT: "1"
          PIP_DEFAULT_TIMEOUT: "100"
        run: |
          python -m pip install -U pip wheel setuptools
          pip install --prefer-binary -r requirements.txt
          pip install --prefer-binary -r requirements-memory.txt || true
          pip install --prefer-binary \
            "FlagEmbedding>=1.2.10" \
            "chromadb==0.5.3" \
            "duckdb==0.10.2" \
            "huggingface_hub[cli]>=0.23" \
            "python-dotenv"

      - name: "Download embeddings (bge-m3)"
        shell: bash
        env:
          HF_TOKEN: "${{ secrets.HF_TOKEN }}"
        run: |
          set -e
          WS="${GITHUB_WORKSPACE:-$PWD}"
          mkdir -p "$WS/models/bge-m3" "$WS/storage/chroma"
          huggingface-cli download \
            --repo-type model BAAI/bge-m3 \
            --local-dir "$WS/models/bge-m3" \
            --local-dir-use-symlinks False
          ls -lh "$WS/models/bge-m3" | head -n 40

      - name: "Preflight: load BGE-M3 locally"
        shell: bash
        run: |
          set -e
          WS="${GITHUB_WORKSPACE:-$PWD}"
          cat > /tmp/_preflight.py <<'PY'
          import os
          from pathlib import Path
          from FlagEmbedding import BGEM3FlagModel
          ws = os.environ.get("WS")
          p = Path(ws) / "models" / "bge-m3"
          print("files:", len(list(p.rglob("*"))))
          _ = BGEM3FlagModel(p.as_posix(), use_fp16=False, device="cpu")
          print("✓ BGE-M3 loaded")
          PY
          WS="${WS}" python - <<'PY'
    import os, subprocess
    subprocess.check_call(["python", "/tmp/_preflight.py"], env={**os.environ, "WS": os.environ.get("WS",".")})
        PY

      - name: "Write CI .env"
        shell: bash
        run: |
          set -e
          WS="${GITHUB_WORKSPACE:-$PWD}"
          mkdir -p "$WS/storage/chroma" "$WS/models/bge-m3"
          cat > .env <<EOF
          ENABLE_MEMORY=true
          AIR4_ENABLE_MEMORY=true
          AIR4_MEMORY_BACKEND=chroma
          AIR4_MEMORY_FORCE_FALLBACK=0
          AIR4_CHROMA_DIR=${WS}/storage/chroma
          CHROMA_DIR=${WS}/storage/chroma
          AIR4_CHROMA_COLLECTION=air4_memory
          AIR4_EMBED_MODEL_PATH=${WS}/models/bge-m3
          AIR4_OFFLINE=0
          AIR4_DEBUG=1
          EOF
          sed -i -e 's/\r$//' .env
          echo "---- .env (first lines) ----"
          sed -n '1,160p' .env

      - name: "Start API (bg)"
        shell: bash
        env:
          UVICORN_CMD: "uvicorn backend.app.main:app --host 127.0.0.1 --port 8000 --log-level debug --env-file .env"
        run: |
          set -e
          ${UVICORN_CMD} > server.log 2>&1 &
          echo $! > .uvicorn.pid
          for i in {1..40}; do
            curl -fsS http://127.0.0.1:8000/health && break || sleep 1
          done
          echo "---- /health after boot ----"
          curl -sS http://127.0.0.1:8000/health || true

      - name: "Health check"
        run: curl -fsS http://127.0.0.1:8000/health

      - name: "Guard: ensure Chroma + embeddings are active (soft)"
        continue-on-error: true
        shell: bash
        run: |
          set -e
          echo "---- .env (dump) ----"
          cat .env
          out="$(curl -fsS http://127.0.0.1:8000/health || true)"
          echo "$out"
          if echo "$out" | grep -q '"memory_backend":"chroma"'; then
            echo "✓ Chroma backend active"
          else
            echo "⚠ Memory backend is NOT 'chroma' (embeddings init failed?)"
            echo "---- tail server.log ----"
            tail -n 300 server.log || true
          fi

      - name: "Sanity: one ingest call (debug)"
        shell: bash
        run: |
          set -e
          echo "Trying single ingest…"
          curl -sS -o /tmp/ingest_resp.json -w "\nHTTP:%{http_code}\n" \
            -F "file=@tests/rag_corpus/docs/noise_finance.txt" \
            http://127.0.0.1:8000/ingest/file || true
          echo "--- ingest response (first 400 chars) ---"
          head -c 400 /tmp/ingest_resp.json || true
          echo
          if jq . /tmp/ingest_resp.json >/dev/null 2>&1; then
            echo "OK: JSON received"
          else
            echo "ERR: not a JSON, see above"
          fi

      - name: "Run smoke"
        shell: bash
        env:
          K: "6"
          MMR: "0.4"
          HYDE: "2"
          THRESHOLD: "0.30"
        run: |
          set -e
          echo "CI params: K=${K} MMR=${MMR} HYDE=${HYDE} THRESHOLD=${THRESHOLD}"
          export K MMR HYDE THRESHOLD
          bash scripts/smoke_phase10_rag.sh

      - name: "Upload smoke log (artifact)"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: "smoke-log"
          path: |
            .smoke.log
            .smoke_phase10_step2.log
            server.log
          if-no-files-found: ignore

      - name: "Teardown"
        if: always()
        shell: bash
        run: |
          if [ -f .uvicorn.pid ]; then kill "$(cat .uvicorn.pid)" || true; fi