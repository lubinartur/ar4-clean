name: "RAG Smoke (Phase-10)"

on:
  push:
    branches: [ "main", "master", "feature/**" ]
  pull_request:
    branches: [ "main", "master" ]
  workflow_dispatch:

concurrency:
  group: "${{ github.workflow }}-${{ github.ref }}"
  cancel-in-progress: true

jobs:
  rag-smoke:
    runs-on: ubuntu-latest
    timeout-minutes: 40

    steps:
      - name: "Checkout"
        uses: actions/checkout@v4

      - name: "Set up Python"
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: "Install deps"
        shell: bash
        env:
          PIP_DISABLE_PIP_VERSION_CHECK: "1"
          PIP_NO_INPUT: "1"
          PIP_DEFAULT_TIMEOUT: "100"
        run: |
          python -m pip install -U pip wheel setuptools
          # базовые зависимостb проекта
          pip install --prefer-binary -r requirements.txt
          pip install --prefer-binary -r requirements-memory.txt || true
          # пины для Chroma/duckdb и нужные утилиты
          pip install --prefer-binary "chromadb==0.5.3" "duckdb==0.10.2" \
                                   "FlagEmbedding>=1.2.10" "python-multipart>=0.0.9" \
                                   "huggingface_hub[cli]>=0.23"
          python -c "import sys; import chromadb, duckdb; print('✓ chromadb', chromadb.__version__); print('✓ duckdb', duckdb.__version__); print('✓ py', sys.version)"

      - name: "Download embeddings (bge-m3)"
        shell: bash
        env:
          HF_TOKEN: "${{ secrets.HF_TOKEN }}"
        run: |
          mkdir -p "${{ github.workspace }}/models/bge-m3" "${{ github.workspace }}/storage/chroma"
          huggingface-cli download \
            --repo-type model BAAI/bge-m3 \
            --local-dir "${{ github.workspace }}/models/bge-m3" \
            --local-dir-use-symlinks False
          ls -lh "${{ github.workspace }}/models/bge-m3" | head -n 20

      - name: "Preflight: load BGE-M3 locally"
        shell: bash
        run: |
          python - <<'PY'
          from pathlib import Path
          from FlagEmbedding import BGEM3FlagModel
          p = Path("${{ github.workspace }}/models/bge-m3")
          print("files:", len(list(p.rglob('*'))))
          _ = BGEM3FlagModel(p.as_posix(), use_fp16=False, device="cpu")
          print("✓ BGE-M3 loaded")
          PY

      - name: "Write CI .env"
        shell: bash
        run: |
          cat > .env <<'ENV'
AIR4_ENABLE_MEMORY=true
ENABLE_MEMORY=true
AIR4_MEMORY_BACKEND=chroma
AIR4_CHROMA_COLLECTION=air4_memory
CHROMA_DIR=${{ github.workspace }}/storage/chroma
AIR4_EMBED_MODEL_PATH=${{ github.workspace }}/models/bge-m3
AIR4_OFFLINE=false
ENV
          # CRLF -> LF и быстрый линт
          sed -i -e 's/\r$//' .env || true
          if ! awk 'BEGIN{ok=1} !/^[A-Z0-9_]+=.*/{print "Bad .env line:",$0; ok=0} END{exit ok?0:1}' .env; then
            echo "::error::.env has invalid lines"; exit 2
          fi
          echo "---- .env (first lines) ----"
          sed -n '1,50p' .env

      - name: "Start API (bg)"
        shell: bash
        env:
          UVICORN_CMD: "uvicorn backend.app.main:app --host 127.0.0.1 --port 8000 --log-level debug"
        run: |
          set -e
          mkdir -p "${{ github.workspace }}/storage/chroma"
          echo "Booting API with --env-file .env"
          $UVICORN_CMD --env-file .env > server.log 2>&1 &
          echo $! > .uvicorn.pid
          for i in {1..30}; do
            curl -fsS http://127.0.0.1:8000/health && break || sleep 1
          done
          echo "---- /health after boot ----"
          curl -sS http://127.0.0.1:8000/health || true

      - name: "Health check"
        shell: bash
        run: curl -fsS http://127.0.0.1:8000/health

      - name: "Guard: ensure Chroma + embeddings are active"
        shell: bash
        run: |
          set -e
          echo "pip show:"
          pip show chromadb duckdb || true
          out="$(curl -fsS http://127.0.0.1:8000/health)"
          echo "$out" | jq . || echo "$out"
          if echo "$out" | grep -q '"memory_backend":"chroma"'; then
            echo "✓ Chroma backend active"
          else
            echo "✗ Memory backend is NOT 'chroma' (embeddings init failed?)"
            echo "---- tail server.log ----"
            tail -n 200 server.log || true
            exit 2
          fi

      - name: "Sanity: one ingest call (debug)"
        shell: bash
        run: |
          set -e
          echo "Trying single ingest…"
          curl -sS -o /tmp/ingest_resp.json -w "\nHTTP:%{http_code}\n" \
            -F "file=@tests/rag_corpus/docs/noise_finance.txt" \
            http://127.0.0.1:8000/ingest/file || true
          echo "--- ingest response (first 400 chars) ---"
          head -c 400 /tmp/ingest_resp.json || true
          echo
          if jq . /tmp/ingest_resp.json >/dev/null 2>&1; then
            echo "OK: JSON received"
          else
            echo "ERR: not a JSON, see above"; exit 5
          fi

      - name: "Run smoke"
        shell: bash
        env:
          # Чуть ниже порога в CI, чтобы флаки не заваливали билд
          K: "6"
          MMR: "0.4"
          HYDE: "2"
          THRESHOLD: "0.30"
        run: |
          echo "CI params: K=${K} MMR=${MMR} HYDE=${HYDE} THRESHOLD=${THRESHOLD}"
          bash scripts/smoke_phase10_rag.sh

      - name: "Upload smoke log (artifact)"
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: "smoke-log"
          path: |
            .smoke.log
            .smoke_phase10_step2.log
            server.log
            .env
          if-no-files-found: ignore

      - name: "Teardown"
        if: always()
        shell: bash
        run: |
          if [ -f .uvicorn.pid ]; then kill "$(cat .uvicorn.pid)" || true; fi